{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781960ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heartRate : Heart rate in beats per minute (bpm).\n",
    "# When : The time of the heart rate sample. \n",
    "# heartBeatIntervals: The most recent beat-to-beat interval data as an Array of Number objects in milliseconds (ms). \n",
    "# Calories: The calories for the day in kilocalories (kCal) \n",
    "# Distance: The distance for the day in centimeters (cm). \n",
    "# Number of floors climbed: The number of floors climbed for the day.\n",
    "# Steps:\n",
    "# stressScore: The current stress score. The stress score calculated using a rolling average of the last 30 seconds of stress level readings.\n",
    "# respirationRate: Current respiration rate for the user, in breaths per minute Value may be null.\n",
    "# timeToRecovery: Time to recover from the last activity, in hours Value may be null.\n",
    "# oxygenSaturation: The current oxygen saturation in percent (%) \n",
    "# temperature: Celsius Â©\n",
    "# Cadence: The cadence in revolutions per minute (rpm).\n",
    "# Pressure: The barometric pressure in Pascals (Pa). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fd129db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ebba8fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Data (First 10 rows):\n",
      "   heartRate  stressScore  respirationRate  oxygenSaturation  temperature  \\\n",
      "0  98.028572    12.330774        17.306245         97.939282    36.726785   \n",
      "1  89.279758    42.508667        15.856715         98.501050    36.766380   \n",
      "2  83.946339    33.363691        17.908568         99.127822          NaN   \n",
      "3  66.240746    60.599069        19.689663         97.034855    37.528720   \n",
      "4  66.239781     2.247671        12.932374         98.434610    36.926638   \n",
      "5  62.323344    45.070755        17.676542         96.516007    38.721889   \n",
      "6  94.647046    53.406421        13.842753         97.177380    37.659419   \n",
      "7  84.044600    53.164060              NaN         99.478136    38.362431   \n",
      "8  88.322903    62.025178        12.262902         99.749538    38.772713   \n",
      "9  60.823380    51.032362        13.087259         98.594087    36.489405   \n",
      "\n",
      "   emergency  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n",
      "5          1  \n",
      "6          0  \n",
      "7          1  \n",
      "8          1  \n",
      "9          0  \n",
      "\n",
      "Emergency Statistics:\n",
      "Total samples: 10000\n",
      "Emergency cases: 3310 (33.1%)\n",
      "Non-emergency cases: 6690 (66.9%)\n",
      "\n",
      "Mean Values for Key Metrics:\n",
      "heartRate: Emergency = 79.88, Normal = 79.77\n",
      "oxygenSaturation: Emergency = 97.51, Normal = 97.48\n",
      "temperature: Emergency = 38.50, Normal = 36.99\n",
      "respirationRate: Emergency = 16.01, Normal = 16.00\n",
      "stressScore: Emergency = 34.89, Normal = 35.58\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def generate_synthetic_data(n_samples=10000, filename='medical_sample_data.csv'):\n",
    "    \"\"\"\n",
    "    Generate synthetic health metrics data with emergency labels and save to CSV\n",
    "    \n",
    "    Parameters:\n",
    "    n_samples (int): Number of data points to generate\n",
    "    filename (str): Name of CSV file to save the data\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Synthetic dataset with health metrics and emergency labels\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Normal ranges for different health metrics\n",
    "    normal_ranges = {\n",
    "        'heartRate': (60, 100),\n",
    "        'stressScore': (0, 70),\n",
    "        'respirationRate': (12, 20),\n",
    "        'oxygenSaturation': (95, 100),\n",
    "        'temperature': (36, 39),\n",
    "    }\n",
    "    \n",
    "    # Create empty dataframe\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    # Generate normal values for most samples\n",
    "    for feature, (min_val, max_val) in normal_ranges.items():\n",
    "        # Generate mostly normal values with some outliers\n",
    "        if np.random.random() < 0.6:  # 60% normal values\n",
    "            data[feature] = np.random.uniform(min_val, max_val, n_samples)\n",
    "        else:  # 40% broader range that might include abnormal values\n",
    "            spread = max_val - min_val\n",
    "            data[feature] = np.random.uniform(min_val - spread*0.8, max_val + spread*0.8, n_samples)\n",
    "    \n",
    "    # Emergency conditions definitions (medical thresholds)\n",
    "    emergency_conditions = [\n",
    "        # High heart rate (tachycardia)\n",
    "        (data['heartRate'] > 120),\n",
    "        # Low heart rate (bradycardia)\n",
    "        (data['heartRate'] < 50),\n",
    "        # Low oxygen saturation\n",
    "        (data['oxygenSaturation'] < 90),\n",
    "        # High temperature (fever)\n",
    "        (data['temperature'] > 38),\n",
    "        # Very low temperature (hypothermia)\n",
    "        (data['temperature'] < 35.0),\n",
    "        # Abnormal respiration (high)\n",
    "        (data['respirationRate'] > 25),\n",
    "        # Abnormal respiration (low)\n",
    "        (data['respirationRate'] < 8),\n",
    "        # Extremely high stress\n",
    "        (data['stressScore'] > 90)\n",
    "    ]\n",
    "    \n",
    "    # Mark as emergency if any condition is true\n",
    "    data['emergency'] = np.logical_or.reduce(emergency_conditions).astype(int)\n",
    "    \n",
    "    # Set some values to None/NaN to simulate missing data\n",
    "    for feature in normal_ranges.keys():\n",
    "        # Randomly set 5% of the values to NaN\n",
    "        data.loc[data.sample(frac=0.05).index, feature] = np.nan\n",
    "    \n",
    "    # Save data to CSV file\n",
    "    data.to_csv(filename, index=False)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Generate 50 samples and display first 10 rows\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate and save data\n",
    "    sample_data = generate_synthetic_data(n_samples=10000)\n",
    "    \n",
    "    # Display first 10 rows\n",
    "    print(\"\\nSample Data (First 10 rows):\")\n",
    "    print(sample_data.head(10))\n",
    "    \n",
    "    # Display statistics about emergencies\n",
    "    emergency_count = sample_data['emergency'].sum()\n",
    "    total_samples = len(sample_data)\n",
    "    print(f\"\\nEmergency Statistics:\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Emergency cases: {emergency_count} ({emergency_count/total_samples:.1%})\")\n",
    "    print(f\"Non-emergency cases: {total_samples - emergency_count} ({(total_samples - emergency_count)/total_samples:.1%})\")\n",
    "    \n",
    "    # Display distribution of key metrics in emergency vs non-emergency cases\n",
    "    print(\"\\nMean Values for Key Metrics:\")\n",
    "    metrics = ['heartRate', 'oxygenSaturation', 'temperature', 'respirationRate', 'stressScore']\n",
    "    for metric in metrics:\n",
    "        emergency_mean = sample_data[sample_data['emergency'] == 1][metric].mean()\n",
    "        normal_mean = sample_data[sample_data['emergency'] == 0][metric].mean()\n",
    "        print(f\"{metric}: Emergency = {emergency_mean:.2f}, Normal = {normal_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "589b2738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   heartRate  stressScore  respirationRate  oxygenSaturation  temperature  \\\n",
      "0  98.028572    12.330774        17.306245         97.939282    36.726785   \n",
      "1  89.279758    42.508667        15.856715         98.501050    36.766380   \n",
      "2  83.946339    33.363691        17.908568         99.127822          NaN   \n",
      "3  66.240746    60.599069        19.689663         97.034855    37.528720   \n",
      "4  66.239781     2.247671        12.932374         98.434610    36.926638   \n",
      "\n",
      "   emergency  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "data = pd.read_csv('medical_sample_data.csv')\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92cb12e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values (you can choose a strategy such as mean, median, mode, or drop rows/columns)\n",
    "data = data.dropna()\n",
    "data.fillna(data.mean(), inplace=True) \n",
    "# Replace missing values with mean\n",
    "\n",
    "# Encoding categorical variables if necessary (example for 'category_column')\n",
    "# data['category_column'] = data['category_column'].map({'category1': 0, 'category2': 1})\n",
    "\n",
    "# Feature scaling (optional, but recommended for algorithms like SVM or KNN)\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(data.drop('emergency', axis=1))\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = scaled_features\n",
    "y = data['emergency']  # Replace with your actual target column name\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0984a681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns=['emergency'])\n",
    "\n",
    "# Target (emergency label)\n",
    "y = data['emergency']\n",
    "\n",
    "# Step 2: Train-Test Split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Feature Scaling (important for many models, though not necessary for Random Forest)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5b031eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1043\n",
      "           1       1.00      1.00      1.00       508\n",
      "\n",
      "    accuracy                           1.00      1551\n",
      "   macro avg       1.00      1.00      1.00      1551\n",
      "weighted avg       1.00      1.00      1.00      1551\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1043    0]\n",
      " [   0  508]]\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Step 6: Model performance statistics\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16d16234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model and scaler\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a927d60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/aaryanpanthi/miniconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/aaryanpanthi/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/aaryanpanthi/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/aaryanpanthi/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/aaryanpanthi/miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.1\n",
      "    Uninstalling scikit-learn-1.5.1:\n",
      "      Successfully uninstalled scikit-learn-1.5.1\n",
      "Successfully installed scikit-learn-1.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4722581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
