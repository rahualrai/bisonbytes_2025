{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781960ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heartRate : Heart rate in beats per minute (bpm).\n",
    "# When : The time of the heart rate sample. \n",
    "# heartBeatIntervals: The most recent beat-to-beat interval data as an Array of Number objects in milliseconds (ms). \n",
    "# Calories: The calories for the day in kilocalories (kCal) \n",
    "# Distance: The distance for the day in centimeters (cm). \n",
    "# Number of floors climbed: The number of floors climbed for the day.\n",
    "# Steps:\n",
    "# stressScore: The current stress score. The stress score calculated using a rolling average of the last 30 seconds of stress level readings.\n",
    "# respirationRate: Current respiration rate for the user, in breaths per minute Value may be null.\n",
    "# timeToRecovery: Time to recover from the last activity, in hours Value may be null.\n",
    "# oxygenSaturation: The current oxygen saturation in percent (%) \n",
    "# temperature: Celsius Â©\n",
    "# Cadence: The cadence in revolutions per minute (rpm).\n",
    "# Pressure: The barometric pressure in Pascals (Pa). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fd129db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebba8fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Data (First 10 rows):\n",
      "   heartRate  heartBeatIntervals     calories      distance  floorsClimbed  \\\n",
      "0  98.028572          670.461565          NaN  11757.128320       4.845236   \n",
      "1  89.279758          842.906668  1928.357378  14004.200300       5.109201   \n",
      "2  83.946339                 NaN  2954.284155  16511.289787       9.114327   \n",
      "3  66.240746                 NaN  3844.831605   8139.420609      10.191464   \n",
      "4  66.239781          612.843832   466.186751  13738.438153       6.177584   \n",
      "5  62.323344          857.547171          NaN   6064.029428      18.145928   \n",
      "6  94.647046          905.179551   921.376623   8709.521847      11.062794   \n",
      "7  84.044600          903.794628  1657.906910  17912.542624      15.749539   \n",
      "8  88.322903          954.429587          NaN  18998.152187      18.484757   \n",
      "9  60.823380          891.613497   543.629529  14376.346939       3.262702   \n",
      "\n",
      "          steps  stressScore  respirationRate  timeToRecovery  \\\n",
      "0   1608.979353    34.054589        22.730419       11.170142   \n",
      "1   9473.759843    14.194186        18.506410        0.220840   \n",
      "2   5603.257334    61.281898        16.598518       21.060878   \n",
      "3   5012.846246    54.671431        20.608822        3.895057   \n",
      "4  14698.733682     9.844702         6.343868       12.020348   \n",
      "5   6486.459641    25.717192         6.877131       22.291836   \n",
      "6  10170.575672    37.949247        19.895289       19.703581   \n",
      "7           NaN    31.803704        12.569455             NaN   \n",
      "8   1564.553263    27.845709        15.767755       14.530695   \n",
      "9           NaN    50.318233        21.865445       10.470564   \n",
      "\n",
      "   oxygenSaturation  temperature     cadence       pressure  emergency  \n",
      "0         96.728835    37.057306   62.081768  101442.276673          0  \n",
      "1         96.464744          NaN   88.098787   99064.252434          0  \n",
      "2         97.136615    36.585201   88.640526  101565.571230          0  \n",
      "3         96.664628    36.267805   99.283734   99276.260157          0  \n",
      "4         99.198457    36.845919  102.386263   98050.087512          1  \n",
      "5         97.903283    36.699827   90.527309  102118.121777          1  \n",
      "6         95.880835    36.501269  102.482104   97311.179100          0  \n",
      "7         96.179728          NaN         NaN   99193.430740          0  \n",
      "8         95.267767    36.285610   68.622109  101035.232545          0  \n",
      "9         96.498443    36.953202  115.888213  102318.181141          0  \n",
      "\n",
      "Emergency Statistics:\n",
      "Total samples: 10000\n",
      "Emergency cases: 1711 (17.1%)\n",
      "Non-emergency cases: 8289 (82.9%)\n",
      "\n",
      "Mean Values for Key Metrics:\n",
      "heartRate: Emergency = 79.45, Normal = 79.85\n",
      "oxygenSaturation: Emergency = 97.47, Normal = 97.49\n",
      "temperature: Emergency = 36.64, Normal = 36.65\n",
      "respirationRate: Emergency = 13.60, Normal = 16.46\n",
      "stressScore: Emergency = 34.90, Normal = 35.32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def generate_synthetic_data(n_samples=10000, filename='medical_sample_data.csv'):\n",
    "    \"\"\"\n",
    "    Generate synthetic health metrics data with emergency labels and save to CSV\n",
    "    \n",
    "    Parameters:\n",
    "    n_samples (int): Number of data points to generate\n",
    "    filename (str): Name of CSV file to save the data\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Synthetic dataset with health metrics and emergency labels\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Normal ranges for different health metrics\n",
    "    normal_ranges = {\n",
    "        'heartRate': (60, 100),\n",
    "        'heartBeatIntervals': (600, 1000),  # milliseconds\n",
    "        'calories': (0, 4000),\n",
    "        'distance': (0, 20000),  # centimeters\n",
    "        'floorsClimbed': (0, 20),\n",
    "        'steps': (0, 15000),\n",
    "        'stressScore': (0, 70),\n",
    "        'respirationRate': (12, 20),\n",
    "        'timeToRecovery': (0, 24),\n",
    "        'oxygenSaturation': (95, 100),\n",
    "        'temperature': (36.1, 37.2),\n",
    "        'cadence': (60, 120),\n",
    "        'pressure': (97000, 103000)  # Pascals\n",
    "    }\n",
    "    \n",
    "    # Create empty dataframe\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    # Generate normal values for most samples\n",
    "    for feature, (min_val, max_val) in normal_ranges.items():\n",
    "        # Generate mostly normal values with some outliers\n",
    "        if np.random.random() < 0.6:  # 60% normal values\n",
    "            data[feature] = np.random.uniform(min_val, max_val, n_samples)\n",
    "        else:  # 40% broader range that might include abnormal values\n",
    "            spread = max_val - min_val\n",
    "            data[feature] = np.random.uniform(min_val - spread*0.8, max_val + spread*0.8, n_samples)\n",
    "    \n",
    "    # Emergency conditions definitions (medical thresholds)\n",
    "    emergency_conditions = [\n",
    "        # High heart rate (tachycardia)\n",
    "        (data['heartRate'] > 120),\n",
    "        # Low heart rate (bradycardia)\n",
    "        (data['heartRate'] < 50),\n",
    "        # Low oxygen saturation\n",
    "        (data['oxygenSaturation'] < 90),\n",
    "        # High temperature (fever)\n",
    "        (data['temperature'] > 38.5),\n",
    "        # Very low temperature (hypothermia)\n",
    "        (data['temperature'] < 35.0),\n",
    "        # Abnormal respiration (high)\n",
    "        (data['respirationRate'] > 25),\n",
    "        # Abnormal respiration (low)\n",
    "        (data['respirationRate'] < 8),\n",
    "        # Extremely high stress\n",
    "        (data['stressScore'] > 90)\n",
    "    ]\n",
    "    \n",
    "    # Mark as emergency if any condition is true\n",
    "    data['emergency'] = np.logical_or.reduce(emergency_conditions).astype(int)\n",
    "    \n",
    "    # Set some values to None/NaN to simulate missing data\n",
    "    for feature in normal_ranges.keys():\n",
    "        # Randomly set 5% of the values to NaN\n",
    "        data.loc[data.sample(frac=0.05).index, feature] = np.nan\n",
    "    \n",
    "    # Save data to CSV file\n",
    "    data.to_csv(filename, index=False)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Generate 50 samples and display first 10 rows\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate and save data\n",
    "    sample_data = generate_synthetic_data(n_samples=10000)\n",
    "    \n",
    "    # Display first 10 rows\n",
    "    print(\"\\nSample Data (First 10 rows):\")\n",
    "    print(sample_data.head(10))\n",
    "    \n",
    "    # Display statistics about emergencies\n",
    "    emergency_count = sample_data['emergency'].sum()\n",
    "    total_samples = len(sample_data)\n",
    "    print(f\"\\nEmergency Statistics:\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Emergency cases: {emergency_count} ({emergency_count/total_samples:.1%})\")\n",
    "    print(f\"Non-emergency cases: {total_samples - emergency_count} ({(total_samples - emergency_count)/total_samples:.1%})\")\n",
    "    \n",
    "    # Display distribution of key metrics in emergency vs non-emergency cases\n",
    "    print(\"\\nMean Values for Key Metrics:\")\n",
    "    metrics = ['heartRate', 'oxygenSaturation', 'temperature', 'respirationRate', 'stressScore']\n",
    "    for metric in metrics:\n",
    "        emergency_mean = sample_data[sample_data['emergency'] == 1][metric].mean()\n",
    "        normal_mean = sample_data[sample_data['emergency'] == 0][metric].mean()\n",
    "        print(f\"{metric}: Emergency = {emergency_mean:.2f}, Normal = {normal_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "589b2738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   heartRate  heartBeatIntervals     calories      distance  floorsClimbed  \\\n",
      "0  98.028572          670.461565          NaN  11757.128320       4.845236   \n",
      "1  89.279758          842.906668  1928.357378  14004.200300       5.109201   \n",
      "2  83.946339                 NaN  2954.284155  16511.289787       9.114327   \n",
      "3  66.240746                 NaN  3844.831605   8139.420609      10.191464   \n",
      "4  66.239781          612.843832   466.186751  13738.438153       6.177584   \n",
      "\n",
      "          steps  stressScore  respirationRate  timeToRecovery  \\\n",
      "0   1608.979353    34.054589        22.730419       11.170142   \n",
      "1   9473.759843    14.194186        18.506410        0.220840   \n",
      "2   5603.257334    61.281898        16.598518       21.060878   \n",
      "3   5012.846246    54.671431        20.608822        3.895057   \n",
      "4  14698.733682     9.844702         6.343868       12.020348   \n",
      "\n",
      "   oxygenSaturation  temperature     cadence       pressure  emergency  \n",
      "0         96.728835    37.057306   62.081768  101442.276673          0  \n",
      "1         96.464744          NaN   88.098787   99064.252434          0  \n",
      "2         97.136615    36.585201   88.640526  101565.571230          0  \n",
      "3         96.664628    36.267805   99.283734   99276.260157          0  \n",
      "4         99.198457    36.845919  102.386263   98050.087512          1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "data = pd.read_csv('medical_sample_data.csv')\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "92cb12e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values (you can choose a strategy such as mean, median, mode, or drop rows/columns)\n",
    "data = data.dropna()\n",
    "data.fillna(data.mean(), inplace=True) \n",
    "# Replace missing values with mean\n",
    "\n",
    "# Encoding categorical variables if necessary (example for 'category_column')\n",
    "# data['category_column'] = data['category_column'].map({'category1': 0, 'category2': 1})\n",
    "\n",
    "# Feature scaling (optional, but recommended for algorithms like SVM or KNN)\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(data.drop('emergency', axis=1))\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = scaled_features\n",
    "y = data['emergency']  # Replace with your actual target column name\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0984a681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns=['emergency'])\n",
    "\n",
    "# Target (emergency label)\n",
    "y = data['emergency']\n",
    "\n",
    "# Step 2: Train-Test Split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Feature Scaling (important for many models, though not necessary for Random Forest)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b031eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1697\n",
      "           1       1.00      0.95      0.97       303\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       1.00      0.97      0.98      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1697    0]\n",
      " [  16  287]]\n",
      "Accuracy: 99.20%\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Step 6: Model performance statistics\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16d16234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model and scaler\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a927d60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/aaryanpanthi/miniconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/aaryanpanthi/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/aaryanpanthi/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/aaryanpanthi/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/aaryanpanthi/miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.1\n",
      "    Uninstalling scikit-learn-1.5.1:\n",
      "      Successfully uninstalled scikit-learn-1.5.1\n",
      "Successfully installed scikit-learn-1.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4722581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
